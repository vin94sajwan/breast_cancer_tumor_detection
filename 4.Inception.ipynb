{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d083daba",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 53] The network path was not found: '//content/drive/MyDrive/Train_Set_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VINEET~1\\AppData\\Local\\Temp/ipykernel_2084/324419073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;31m# Load and preprocess the training and test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[0mtrain_data_directory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                 \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m         \"\"\"\n\u001b[1;32m-> 1650\u001b[1;33m         return DirectoryIterator(\n\u001b[0m\u001b[0;32m   1651\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 53] The network path was not found: '//content/drive/MyDrive/Train_Set_2'"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch  # Import the torch module\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score,precision_score\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report,accuracy_score,f1_score,precision_score\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3,MobileNet\n",
    "\n",
    "# Step 1: Preprocess and load the WSI data\n",
    "train_data_directory = '//content/drive/MyDrive/Train_Set_2'  # Directory containing training patches\n",
    "test_data_directory = '//content/drive/MyDrive/Test'    # Directory containing test patches\n",
    "\n",
    "img_height, img_width = 299, 299  # InceptionV3 input size\n",
    "batch_size = 32\n",
    "num_classes = 3  # Number of classes: cancerous, precancerous, and non-cancerous\n",
    "\n",
    "# Define Albumentations transformations\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(img_height, img_width),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(img_height, img_width),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Create custom data loaders using Albumentations and PyTorch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class CustomDataset(datasets.ImageFolder):\n",
    "    def __init__(self, data_directory, transform=None):\n",
    "        super().__init__(root=data_directory, transform=transform)\n",
    "\n",
    "\n",
    "# Create ImageDataGenerator for data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load and preprocess the training and test data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_directory,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess the training and test data using Albumentations\n",
    "train_dataset = CustomDataset(train_data_directory, transform=train_transform)\n",
    "test_dataset = CustomDataset(test_data_directory, transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Load the InceptionV3 model and modify it for transfer learning\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer with 1024 units and ReLU activation\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a final softmax layer for multi-class classification\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the new layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Step 3: Freeze some layers in the base model for transfer learning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Step 4: Compile and train the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10  # Choose the number of epochs suitable for your dataset\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Step 5: Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator, steps=None)\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Step 6: Compute category-wise accuracy and F1 score\n",
    "y_true = test_generator.classes\n",
    "y_pred = model.predict(test_generator, steps=None).argmax(axis=1)\n",
    "\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Compute category-wise accuracy\n",
    "accuracy_per_class = {}\n",
    "for class_name in class_names:\n",
    "  indices = np.where(y_true == test_generator.class_indices[class_name])[0]\n",
    "  accuracy_per_class[class_name] = np.mean(y_true[indices] == y_pred[indices])\n",
    "\n",
    "print(\"Category-wise Accuracy:\")\n",
    "for class_name, acc in accuracy_per_class.items():\n",
    "  print(f\"{class_name}: {acc:.2f}\")\n",
    "\n",
    "# Compute category-wise F1 score\n",
    "f1_per_class = {}\n",
    "for class_name in class_names:\n",
    "  indices = np.where(y_true == test_generator.class_indices[class_name])[0]\n",
    "  f1_per_class[class_name] = f1_score(y_true[indices], y_pred[indices], average='weighted')\n",
    "\n",
    "print(\"\\nCategory-wise F1 Score:\")\n",
    "for class_name, f1 in f1_per_class.items():\n",
    "  print(f\"{class_name}: {f1:.2f}\")\n",
    "\n",
    "# Compute overall accuracy and F1 score\n",
    "overall_accuracy = np.mean(y_true == y_pred)\n",
    "overall_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(\"\\nOverall Accuracy:\", overall_accuracy)\n",
    "print(\"Overall F1 Score:\", overall_f1)\n",
    "\n",
    "# Step 7: Check count of images in each category in test data\n",
    "test_data_counts = {}\n",
    "for class_name in class_names:\n",
    "    class_directory = os.path.join(test_data_directory, class_name)\n",
    "    num_images = len(os.listdir(class_directory))\n",
    "    test_data_counts[class_name] = num_images\n",
    "\n",
    "print(\"\\nCount of Images in Each Category in Test Data:\")\n",
    "for class_name, count in test_data_counts.items():\n",
    "    print(f\"{class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import keras\n",
    "\n",
    "def get_top_predicted_indices(predictions, top_n):\n",
    "    return np.argsort(-predictions).squeeze()[:top_n]\n",
    "\n",
    "def make_gradcam_heatmap(\n",
    "    img_array, model,\n",
    "    last_conv_layer_name,\n",
    "    classifier_layer_names,\n",
    "    top_n,\n",
    "    class_indices\n",
    "):\n",
    "    #1. Create a model that maps the input image to the activations of the last convolution layer - Get last conv layer's output dimensions\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    #2. Create another model, that maps from last convolution layer to the final class predictions - This is the classifier model that calculated the gradient\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    #3. If top N predictions are to be interospected, Get their Imagenet indices else assign the indices given\n",
    "    if(top_n > 0):\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        class_indices = get_top_predicted_indices(preds, top_n)\n",
    "    else:\n",
    "        top_n = len(class_indices)\n",
    "\n",
    "    #4. Create an array to store the heatmaps\n",
    "    heatmaps = []\n",
    "    #5. Iteratively calculate heatmaps for all classes of interest using GradientTape\n",
    "    for index in np.arange(top_n):\n",
    "\n",
    "        #6. Watch the last convolution output during the prediction process to calculate the gradients\n",
    "        #7. Compute the activations of last conv layer and make the tape to watch\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Compute activations of the last conv layer and make the tape watch it\n",
    "            last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "            tape.watch(last_conv_layer_output)\n",
    "\n",
    "            #8. Get the class predictions and the class channel using the class index\n",
    "            preds = classifier_model(last_conv_layer_output)\n",
    "            class_channel = preds[:, class_indices[index]]\n",
    "\n",
    "        #9. Using tape, Get the gradient for the predicted class wrt the output feature map of last conv layer\n",
    "        grads = tape.gradient(\n",
    "            class_channel,\n",
    "            last_conv_layer_output\n",
    "        )\n",
    "\n",
    "        #10. Calculate the mean intensity of the gradient over its feature map channel\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "        last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "        pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "        #11. Multiply each channel in feature map array by weight importance of the channel\n",
    "        for i in range(pooled_grads.shape[-1]):\n",
    "            last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "        #12. The channel-wise mean of the resulting feature map is our heatmap of class activation\n",
    "        heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "        #13. Normalize the heatmap between [0, 1] for ease of visualization\n",
    "        heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "\n",
    "        heatmaps.append({\n",
    "            \"class_id\": class_indices[index],\n",
    "            \"heatmap\": heatmap\n",
    "        })\n",
    "\n",
    "    return heatmaps\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the image from file\n",
    "image_path = \"/content/drive/MyDrive/WSIs/Cancerous/BRACS_1003699.jpg\"\n",
    "image = Image.open(image_path)\n",
    "new_image = image.resize((299, 299))\n",
    "imgdata = np.array(new_image)\n",
    "imgdata = np.expand_dims(imgdata, axis=0)\n",
    "y_pred = model.predict(imgdata)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred\n",
    "\n",
    "\n",
    "import keras.utils as image\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    img = image.load_img(img_path, target_size=size)\n",
    "    array = image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "LAST_CONV_LAYER = 'block5_conv3'\n",
    "CLASSIFIER_LAYER_NAMES = [\n",
    "            \"block5_pool\",\n",
    "            \"global_average_pooling2d_2\",\n",
    "            \"dense_4\",\n",
    "            \"dense_5\"\n",
    "        ]\n",
    "\n",
    "# Calculate Heatmaps for TOP_N Predictions\n",
    "heatmaps = make_gradcam_heatmap(\n",
    "    get_img_array(image_path, (299, 299)),\n",
    "    model,\n",
    "    'block5_conv3',\n",
    "    CLASSIFIER_LAYER_NAMES,\n",
    "    3,\n",
    "    None\n",
    ")\n",
    "\n",
    "CLASS_DICT = {'0':'Cancerous','1':'Non Cancerous','2':'Pre Cancerous'}\n",
    "def display_superimposed_heatmaps(heatmaps, image_path, image_id):\n",
    "    n = len(heatmaps)\n",
    "    n_rows = (n // 3) + 1 if n % 3 > 0 else n // 3\n",
    "    plt.rcParams['axes.grid'] = False\n",
    "    plt.rcParams['xtick.labelsize'] = False\n",
    "    plt.rcParams['ytick.labelsize'] = False\n",
    "    plt.rcParams['xtick.top'] = False\n",
    "    plt.rcParams['xtick.bottom'] = False\n",
    "    plt.rcParams['ytick.left'] = False\n",
    "    plt.rcParams['ytick.right'] = False\n",
    "    plt.rcParams['figure.figsize'] = [30, 15]\n",
    "    for index in np.arange(n):\n",
    "        heatmap = heatmaps[index][\"heatmap\"]\n",
    "        class_id = heatmaps[index][\"class_id\"]\n",
    "        class_name = CLASS_DICT[str(class_id)].split(\",\")[0].capitalize()\n",
    "        superimposed_image = superimpose_heatmap(image_path, heatmap)\n",
    "        plt.subplot(n_rows, 3, index+1)\n",
    "        plt.title(f\"{class_id}, {class_name}\", fontsize= 30)\n",
    "        plt.imshow(superimposed_image)\n",
    "\n",
    "    plt.show()\n",
    "display_superimposed_heatmaps(heatmaps, image_path, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
